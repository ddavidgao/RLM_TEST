{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79e214ee-e91a-466d-a880-28bb8635f4bd",
   "metadata": {},
   "source": [
    "# This script seeks to create a transformer by taking it from the Tiny Shakespeare's Dataset to generate infinite (but completely random) Shakespeare-like text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a009c9-6674-43a0-8113-07bd7000458f",
   "metadata": {},
   "source": [
    "## First, lets import the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92c5c75-e062-468d-b6b8-a96eafd59702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2026-02-06 20:30:56--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2026-02-06 20:30:56 (12.2 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de243eed-839c-47ad-a351-cf8642a5d48f",
   "metadata": {},
   "source": [
    "### Now lets read it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00799539-60fa-46b4-82ac-9a790feef598",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding = 'utf-8') as f:\n",
    "    text = f.read() #saves the entire file to one large string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb45c3d1-d9ad-43c6-83b3-01b29265515c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset in characters: 1115394\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of dataset in characters: {len(text)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0735a1-ff36-48a6-aadf-0b8a8a5fdc34",
   "metadata": {},
   "source": [
    "Then lets fetch the unique characters in this text to fetch our vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a11fec45-202e-4246-b228-ecd5e76e69be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_amount = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1799385-061e-47ff-bb9c-ebf92318afd3",
   "metadata": {},
   "source": [
    "Now lets try to tokenize the input text from raw text to some vector of notebooks from the vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c82046-0723-4fe9-baaf-4d5e5eb5f4e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 6, 1, 42, 39, 60, 47, 42, 1, 47, 57, 1, 39, 61, 43, 57, 53, 51, 43]\n",
      "hello, david is awesome\n"
     ]
    }
   ],
   "source": [
    "str_int = { ch : i for i, ch in enumerate(chars) } # for encoding\n",
    "int_str = { i : ch for i, ch in enumerate(chars) } # for decoding\n",
    "encode = lambda s: [str_int[ch] for ch in s]\n",
    "decode = lambda i: ''.join(int_str[d] for d in i)\n",
    "\n",
    "# let's test it out\n",
    "\n",
    "print(encode(\"hello, david is awesome\"))\n",
    "print(decode(encode(\"hello, david is awesome\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f7e1a9-b9f6-45b6-b2df-06030b7d803e",
   "metadata": {},
   "source": [
    "To encode the entire test dataset we need to import PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19ed1abe-ab57-4567-bca2-c222096f41c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3278d6b6-622c-4404-aec4-cec0034603c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype = torch.long) # Take all of the text from tiny shakespeare and encode it, then wrap to a tensor.\n",
    "\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000]) # Only the first 1,000 characters tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249af8be-567e-4a72-8577-c8075a92d579",
   "metadata": {},
   "source": [
    "Let's now seperate our data into train and validation sets. Specifically a 90-10 split.\n",
    "This means that we will keep 90% of the data and withhold the last 10% to validate so \n",
    "we can see how much it overfits as we don't want this LLM memorizing the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "534f8549-0798-487f-9fd4-970c6898cf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003854\n"
     ]
    }
   ],
   "source": [
    "n = int(.9 * len(data))\n",
    "print(n)\n",
    "train = data[:n]\n",
    "val = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc07ab76-c747-44ba-8296-174409829b67",
   "metadata": {},
   "source": [
    "### Now its time to actually implement a transformer to train and learn these patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f44fd9-6bdc-48c3-b4ea-022b93fd8449",
   "metadata": {},
   "source": [
    "#### It's important to note that training transformers isn't just slapping the entire dataset in because when the data is large that can be very computationally demanding. Instead, we only work with \"chunks\" of the data instead, and sample random chunks out of the set to train chunks of length k at max, which typically is referred to as \"block_size\", or \"context_length\". In our example block_size will be 8. But in modern days block_size has advanced from sizes of 512-2048 in GPT-3 to 8k-128K+ in models like Opus 4.6 due to improvements in attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e401783-bb4a-446f-bc12-a427cae2b166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train[:block_size + 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248f64f-e864-42b4-83e8-2d8e85c45a38",
   "metadata": {},
   "source": [
    "We pack 9 indexes in this example because transformers update as they traverse the data. Therefore 9 indexes results in 8 interactions. \n",
    "\n",
    "e.g: \\\n",
    "We see 18, and contextualize that 47 likely comes next. \\\n",
    "We see 18, 47, then contextualize that 56 likely comes next, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c04645aa-c540-4c08-8613-1b0e4de96c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the input is tensor([18]) the target is 47.\n",
      "When the input is tensor([18, 47]) the target is 56.\n",
      "When the input is tensor([18, 47, 56]) the target is 57.\n",
      "When the input is tensor([18, 47, 56, 57]) the target is 58.\n",
      "When the input is tensor([18, 47, 56, 57, 58]) the target is 1.\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1]) the target is 15.\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15]) the target is 47.\n",
      "When the input is tensor([18, 47, 56, 57, 58,  1, 15, 47]) the target is 58.\n"
     ]
    }
   ],
   "source": [
    "x = train[:block_size]\n",
    "y = train[1:block_size + 1]\n",
    "\n",
    "for i in range(block_size):\n",
    "    context = x[:i + 1]\n",
    "    target = y[i]\n",
    "    print(f\"When the input is {context} the target is {target}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae2d6df-489e-4137-805e-be6bd1786da9",
   "metadata": {},
   "source": [
    "Note: the for loop is for visualization, but blocks x and y are what are actually fed into PyTorch. \\\n",
    "Imagine an input x, a block containing [0, 1, 2, 3, 4, 5, 6, 7]  \\\n",
    "And a target y, another block containing [1, 2, 3, 4, 5, 6, 7, 8] \\\n",
    "The model predicts what the next token would be at each position (without looking into the future), then compares the prediction against y to compute loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50717459-8064-48b7-891c-562086ca61cf",
   "metadata": {},
   "source": [
    "#### The cool part about GPU's is that many cores can work on completely seperate things without ever having to communicate with each other, so now let's generalize the above example to a wider scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0bf86ab6-5639-4cd6-88a6-f9e539edde61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337) # sets the random seed so that we can get the same result for example purposes.\n",
    "batch_size = 4 # 4 concurrent processes that forward-pass and backwards-pass\n",
    "block_size = 8 # max context length of 8 in predictions\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train if split == 'train' else val # we are shadowing the global data. this is just some random local \"data variable\"\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,)) # Here you can see that duplicate data IS possible, but that is the point. We want completely random data\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edb9d35-67a9-4ca3-95b9-9aae40b88ee2",
   "metadata": {},
   "source": [
    "Lets try it out: you should see that the targets are just offset by 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "133b939b-15a9-4a33-b3b8-6495725f0bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[24, 43, 58,  5, 57,  1, 46, 43],\n",
      "        [44, 53, 56,  1, 58, 46, 39, 58],\n",
      "        [52, 58,  1, 58, 46, 39, 58,  1],\n",
      "        [25, 17, 27, 10,  0, 21,  1, 54]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[43, 58,  5, 57,  1, 46, 43, 39],\n",
      "        [53, 56,  1, 58, 46, 39, 58,  1],\n",
      "        [58,  1, 58, 46, 39, 58,  1, 46],\n",
      "        [17, 27, 10,  0, 21,  1, 54, 39]])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print(f'inputs:\\n{xb.shape}\\n{xb}\\ntargets:\\n{yb.shape}\\n{yb}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb6c64e-1316-4f33-95f4-3ae641ece285",
   "metadata": {},
   "source": [
    "#### This gives us 4 completely independent examples (x) that will be fed into the transformer which will then be compared to our targets (y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4684741c-b41b-4aef-a6fc-84f31edc15f1",
   "metadata": {},
   "source": [
    "### Now it's time to feed this to a neural network. For simplicity we will use the bigram language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1a8c1-9f44-408f-908c-643ed0457269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # Neural Network\n",
    "from torch.nn import functional as F # A version of nn where you give it your own weights instead of it usings its own"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
